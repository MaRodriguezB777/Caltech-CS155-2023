{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set5/set5_prob2.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "!wget -O train.txt https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set5/data/train.txt\n",
    "!wget -O test.txt https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set5/data/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C:\n",
    "Fill in these functions to train your SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * Ui) - Vj * (Yij - np.dot(Ui, Vj)))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * Vj) - Ui * (Yij - np.dot(Ui, Vj)))\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    prod = U * V.T\n",
    "    error = np.diff(prod, Y)\n",
    "    np.square(error)\n",
    "    return np.mean(error)\n",
    "\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    U, V = np.random.rand(M, K), np.random.rand(N, K)\n",
    "    U = U - 0.5\n",
    "    V = V - 0.5\n",
    "    error = get_err(U, V, Y, reg)\n",
    "    for epoch in max_epochs:\n",
    "        for (i, j, Yij) in Y:\n",
    "            U[i] = U[i] - grad_U(U[i], Yij, V[j], reg, eta)\n",
    "            V[j] = V[j] - grad_V(V[j], Yij, U[i], reg, eta)\n",
    "\n",
    "        new_error = get_err(U, V, Y, reg)\n",
    "\n",
    "        if(new_error - error) < eps:\n",
    "            error = new_error\n",
    "            break\n",
    "\n",
    "    return U, V, error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D:\n",
    "Run the cell below to get your graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "train.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mtrain.txt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      2\u001b[0m Y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mtest.txt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      4\u001b[0m M \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mmax\u001b[39m(Y_train[:,\u001b[39m0\u001b[39m]), \u001b[39mmax\u001b[39m(Y_test[:,\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m) \u001b[39m# users\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:1313\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1311\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1313\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[0;32m   1314\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m   1315\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1316\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[0;32m   1318\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:955\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    953\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fname)\n\u001b[0;32m    954\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 955\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m         encoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: train.txt not found."
     ]
    }
   ],
   "source": [
    "Y_train = np.loadtxt('train.txt').astype(int)\n",
    "Y_test = np.loadtxt('test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "Ks = [10,20,30,50,100]\n",
    "\n",
    "reg = 0.0\n",
    "eta = 0.03 # learning rate\n",
    "E_in = []\n",
    "E_out = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "for K in Ks:\n",
    "    U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
    "    E_in.append(err)\n",
    "    E_out.append(get_err(U, V, Y_test))\n",
    "\n",
    "plt.plot(Ks, E_in, label='$E_{in}$')\n",
    "plt.plot(Ks, E_out, label='$E_{out}$')\n",
    "plt.title('Error vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.savefig('2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2E:\n",
    "Run the cell below to get your graphs. This might take a long time to run, but it should take less than 2 hours. I would encourage you to validate your 2C is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.loadtxt('train.txt').astype(int)\n",
    "Y_test = np.loadtxt('test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "Ks = [10,20,30,50,100]\n",
    "\n",
    "regs = [10**-4, 10**-3, 10**-2, 10**-1, 1]\n",
    "eta = 0.03 # learning rate\n",
    "E_ins = []\n",
    "E_outs = []\n",
    "\n",
    "# Use to compute Ein and Eout\n",
    "for reg in regs:\n",
    "    E_ins_for_lambda = []\n",
    "    E_outs_for_lambda = []\n",
    "\n",
    "    for k in Ks:\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, k, eta, reg))\n",
    "        U,V, e_in = train_model(M, N, k, eta, reg, Y_train)\n",
    "        E_ins_for_lambda.append(e_in)\n",
    "        eout = get_err(U, V, Y_test)\n",
    "        E_outs_for_lambda.append(eout)\n",
    "\n",
    "    E_ins.append(E_ins_for_lambda)\n",
    "    E_outs.append(E_outs_for_lambda)\n",
    "\n",
    "\n",
    "# Plot values of E_in across k for each value of lambda\n",
    "for i in range(len(regs)):\n",
    "    plt.plot(Ks, E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
    "plt.title('$E_{in}$ vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.savefig('2e_ein.png')\t\n",
    "plt.clf()\n",
    "\n",
    "# Plot values of E_out across k for each value of lambda\n",
    "for i in range(len(regs)):\n",
    "    plt.plot(Ks, E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
    "plt.title('$E_{out}$ vs. K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\t\n",
    "plt.savefig('2e_eout.png')\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
